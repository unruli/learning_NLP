{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"# Natural Language Classification\n\nYou did such a great job for DeFalco's restaurant in the previous exercise that the chef has hired you for a new project.\n\nThe restaurant's menu includes an email address where visitors can give feedback about their food. \n\nThe manager wants you to create a tool that automatically sends him all the negative reviews so he can fix them, while automatically sending all the positive reviews to the owner, so the manager can ask for a raise. \n\nYou will first build a model to distinguish positive reviews from negative reviews using Yelp reviews because these reviews include a rating with each review. Your data consists of the text body of each review along with the star rating. Ratings with 1-2 stars count as \"negative\", and ratings with 4-5 stars are \"positive\". Ratings with 3 stars are \"neutral\" and have been dropped from the data.\n\nLet's get started. First, run the next code cell.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.nlp.ex2 import *\nprint(\"\\nSetup complete\")","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:00:33.947237Z","iopub.execute_input":"2021-11-13T00:00:33.947549Z","iopub.status.idle":"2021-11-13T00:00:44.317624Z","shell.execute_reply.started":"2021-11-13T00:00:33.947466Z","shell.execute_reply":"2021-11-13T00:00:44.316716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 1: Evaluate the Approach\n\nIs there anything about this approach that concerns you? After you've thought about it, run the function below to see one point of view.","metadata":{}},{"cell_type":"code","source":"\nstep_1.solution()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:00:44.319681Z","iopub.execute_input":"2021-11-13T00:00:44.319988Z","iopub.status.idle":"2021-11-13T00:00:44.328622Z","shell.execute_reply.started":"2021-11-13T00:00:44.319949Z","shell.execute_reply":"2021-11-13T00:00:44.32791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Review Data and Create the model\n\nMoving forward with your plan, you'll need to load the data. Here's some basic code to load data and split it into a training and validation set. Run this code.","metadata":{}},{"cell_type":"code","source":"def load_data(csv_file, split=0.9):\n    data = pd.read_csv(csv_file)\n    \n    # Shuffle data\n    train_data = data.sample(frac=1, random_state=7)\n    \n    texts = train_data.text.values\n    labels = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)}\n              for y in train_data.sentiment.values]\n    split = int(len(train_data) * split)\n    \n    train_labels = [{\"cats\": labels} for labels in labels[:split]]\n    val_labels = [{\"cats\": labels} for labels in labels[split:]]\n    \n    return texts[:split], train_labels, texts[split:], val_labels\n\ntrain_texts, train_labels, val_texts, val_labels = load_data('../input/nlp-course/yelp_ratings.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:00:44.329942Z","iopub.execute_input":"2021-11-13T00:00:44.330368Z","iopub.status.idle":"2021-11-13T00:00:44.791184Z","shell.execute_reply.started":"2021-11-13T00:00:44.33033Z","shell.execute_reply":"2021-11-13T00:00:44.790414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You will use this training data to build a model. The code to build the model is the same as what you saw in the tutorial. So that is copied below for you.\n\nFirst, run the cell below to look at a couple elements from your training data.","metadata":{}},{"cell_type":"code","source":"print('Texts from training data\\n------')\nprint(train_texts[:2])\nprint('\\nLabels from training data\\n------')\nprint(train_labels[:2])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:00:44.792486Z","iopub.execute_input":"2021-11-13T00:00:44.792874Z","iopub.status.idle":"2021-11-13T00:00:44.801762Z","shell.execute_reply.started":"2021-11-13T00:00:44.792812Z","shell.execute_reply":"2021-11-13T00:00:44.800853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But because your data is different, there are **two lines in the modeling code cell that you'll need to change.** Can you figure out what they are? \n\nIf you're not sure, take a second look at the data, and pay particular attention to the labels that should be fed to the text classifier.","metadata":{}},{"cell_type":"code","source":"import spacy\n\n# Create an empty model\nnlp = spacy.blank('en')\n\n# Add the TextCategorizer to the empty modelNEGATIVEPOSITIVE\ntextcat = nlp.add_pipe('textcat')\n\n# Add labels to text classifier\ntextcat.add_label(\"NEGATIVE\")\ntextcat.add_label(\"POSITIVE\")\n\n# Check your answer\nstep_2.check()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:00:44.804331Z","iopub.execute_input":"2021-11-13T00:00:44.809314Z","iopub.status.idle":"2021-11-13T00:00:45.143099Z","shell.execute_reply.started":"2021-11-13T00:00:44.809276Z","shell.execute_reply":"2021-11-13T00:00:45.142459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:00:45.144274Z","iopub.execute_input":"2021-11-13T00:00:45.144587Z","iopub.status.idle":"2021-11-13T00:00:45.148572Z","shell.execute_reply.started":"2021-11-13T00:00:45.14455Z","shell.execute_reply":"2021-11-13T00:00:45.147526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3: Train Function\n\nImplement a function `train` that updates a model with training data. Most of this is general data munging, which we've filled in for you. \n\nJust add the one line of code necessary to update your model.","metadata":{}},{"cell_type":"code","source":"import random\nfrom spacy.util import minibatch\nfrom spacy.training.example import Example\n\ndef train(model, train_data, optimizer, batch_size=8):\n    losses = {}\n    random.seed(1)\n    random.shuffle(train_data)\n    \n    # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n    for batch in minibatch(train_data, size=batch_size):\n        # Split batch into text and labels\n        for text, labels in batch:\n            doc = nlp.make_doc(text)\n            example = Example.from_dict(doc, labels)\n            # TODO: Update model with texts and labels\n            model.update([example], sgd=optimizer, losses=losses)\n        \n    return losses\n\nstep_3.check()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:00:45.149885Z","iopub.execute_input":"2021-11-13T00:00:45.150652Z","iopub.status.idle":"2021-11-13T00:01:14.651262Z","shell.execute_reply.started":"2021-11-13T00:00:45.150615Z","shell.execute_reply":"2021-11-13T00:01:14.650615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nstep_3.solution()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:01:14.652441Z","iopub.execute_input":"2021-11-13T00:01:14.652761Z","iopub.status.idle":"2021-11-13T00:01:14.661288Z","shell.execute_reply.started":"2021-11-13T00:01:14.652723Z","shell.execute_reply":"2021-11-13T00:01:14.660346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fix seed for reproducibility\nspacy.util.fix_random_seed(1)\nrandom.seed(1)\n\n# This may take a while to run!\noptimizer = nlp.begin_training()\ntrain_data = list(zip(train_texts, train_labels))\nlosses = train(nlp, train_data, optimizer)\nprint(losses['textcat'])","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:01:14.662742Z","iopub.execute_input":"2021-11-13T00:01:14.663279Z","iopub.status.idle":"2021-11-13T00:11:54.794254Z","shell.execute_reply.started":"2021-11-13T00:01:14.663242Z","shell.execute_reply":"2021-11-13T00:11:54.793457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can try this slightly trained model on some example text and look at the probabilities assigned to each label.","metadata":{}},{"cell_type":"code","source":"text = \"This tea cup was full of holes. Do not recommend.\"\ndoc = nlp(text)\nprint(doc.cats)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:11:54.795808Z","iopub.execute_input":"2021-11-13T00:11:54.796083Z","iopub.status.idle":"2021-11-13T00:11:54.805118Z","shell.execute_reply.started":"2021-11-13T00:11:54.796047Z","shell.execute_reply":"2021-11-13T00:11:54.804163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These probabilities look reasonable. Now you should turn them into an actual prediction.\n\n# Step 4: Making Predictions\n\nImplement a function `predict` that predicts the sentiment of text examples. \n- First, tokenize the texts using `nlp.tokenizer()`. \n- Then, pass those docs to the TextCategorizer which you can get from `nlp.get_pipe()`. \n- Use the `textcat.predict()` method to get scores for each document, then choose the class with the highest score (probability) as the predicted class.","metadata":{}},{"cell_type":"code","source":"def predict(nlp, texts): \n    # Use the model's tokenizer to tokenize each input text\n    docs = [nlp.tokenizer(text) for text in texts]\n\n    # Use textcat to get the scores for each doc\n    textcat = nlp.get_pipe(\"textcat\")\n    scores = textcat.predict(docs)\n\n    # From the scores, find the class with the highest score/probability\n    predicted_class = scores.argmax(axis=1)\n\n    return predicted_class\n\nstep_4.check()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:11:54.806863Z","iopub.execute_input":"2021-11-13T00:11:54.807129Z","iopub.status.idle":"2021-11-13T00:12:10.760591Z","shell.execute_reply.started":"2021-11-13T00:11:54.807093Z","shell.execute_reply":"2021-11-13T00:12:10.759866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nstep_4.solution()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:12:10.761821Z","iopub.execute_input":"2021-11-13T00:12:10.762156Z","iopub.status.idle":"2021-11-13T00:12:10.76933Z","shell.execute_reply.started":"2021-11-13T00:12:10.762117Z","shell.execute_reply":"2021-11-13T00:12:10.768625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = val_texts[34:38]\npredictions = predict(nlp, texts)\n\nfor p, t in zip(predictions, texts):\n    print(f\"{textcat.labels[p]}: {t} \\n\")","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:12:10.770692Z","iopub.execute_input":"2021-11-13T00:12:10.771107Z","iopub.status.idle":"2021-11-13T00:12:10.789009Z","shell.execute_reply.started":"2021-11-13T00:12:10.771068Z","shell.execute_reply":"2021-11-13T00:12:10.788255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like your model is working well after going through the data just once. However you need to calculate some metric for the model's performance on the hold-out validation data.\n\n# Step 5: Evaluate The Model\n\nImplement a function that evaluates a `TextCategorizer` model. This function `evaluate` takes a model along with texts and labels. It returns the accuracy of the model, which is the number of correct predictions divided by all predictions.\n\nFirst, use the `predict` method you wrote earlier to get the predicted class for each text in `texts`. Then, find where the predicted labels match the true \"gold-standard\" labels and calculate the accuracy.","metadata":{}},{"cell_type":"code","source":"\n    def evaluate(model, texts, labels):\n        # Get predictions from textcat model\n        predicted_class = predict(model, texts)\n\n        # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n        true_class = [int(each['cats']['POSITIVE']) for each in labels]\n\n        # A boolean or int array indicating correct predictions\n        correct_predictions = predicted_class == true_class\n\n        # The accuracy, number of correct predictions divided by all predictions\n        accuracy = correct_predictions.mean()\n\n        return accuracy\n\n\nstep_5.check()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:12:10.792242Z","iopub.execute_input":"2021-11-13T00:12:10.79249Z","iopub.status.idle":"2021-11-13T00:12:25.938453Z","shell.execute_reply.started":"2021-11-13T00:12:10.792457Z","shell.execute_reply":"2021-11-13T00:12:25.937765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#step_5.hint()\nstep_5.solution()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:12:25.93994Z","iopub.execute_input":"2021-11-13T00:12:25.9402Z","iopub.status.idle":"2021-11-13T00:12:25.951069Z","shell.execute_reply.started":"2021-11-13T00:12:25.940164Z","shell.execute_reply":"2021-11-13T00:12:25.95023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = evaluate(nlp, val_texts, val_labels)\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:12:25.952619Z","iopub.execute_input":"2021-11-13T00:12:25.953047Z","iopub.status.idle":"2021-11-13T00:12:36.249569Z","shell.execute_reply.started":"2021-11-13T00:12:25.95301Z","shell.execute_reply":"2021-11-13T00:12:36.24882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the functions implemented, you can train and evaluate in a loop.","metadata":{}},{"cell_type":"code","source":"# This may take a while to run!\nn_iters = 5\nfor i in range(n_iters):\n    losses = train(nlp, train_data, optimizer)\n    accuracy = evaluate(nlp, val_texts, val_labels)\n    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-13T00:12:36.250735Z","iopub.execute_input":"2021-11-13T00:12:36.251423Z","iopub.status.idle":"2021-11-13T01:10:06.347556Z","shell.execute_reply.started":"2021-11-13T00:12:36.251385Z","shell.execute_reply":"2021-11-13T01:10:06.346799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6: Keep Improving\n\nYou've built the necessary components to train a text classifier with spaCy. What could you do further to optimize the model?\n\n","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nstep_6.solution()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T01:10:06.348897Z","iopub.execute_input":"2021-11-13T01:10:06.349302Z","iopub.status.idle":"2021-11-13T01:10:06.357342Z","shell.execute_reply.started":"2021-11-13T01:10:06.349264Z","shell.execute_reply":"2021-11-13T01:10:06.356408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}